{
    "type": "openai_chat",
    "model": "TheBloke/Llama-2-70b-Chat-AWQ",
    "max_tokens": 100,
    "temperature": 0,
    "top_p": 1,
    "stop": ["\n"],
    "presence_penalty": null,
    "frequency_penalty": null,
    "best_of": null
}