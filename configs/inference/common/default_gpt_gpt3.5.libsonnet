{
    "type": "openai_chat",
    "model": "gpt-3.5-turbo-0613",
    "max_tokens": 100,
    "temperature": 0,
    "use_cache": true,
    "top_p": 1,
    "stop": ["\n"]
}